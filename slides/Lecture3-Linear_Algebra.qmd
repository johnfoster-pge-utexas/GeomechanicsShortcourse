# Linear Algebra Basics

---

## Matrix-Vector multiplication

\begin{equation}
  \left\{\begin{matrix}
  c_1 \\
  c_2 \\
  c_3 
  \end{matrix}\right\} = 
  \begin{bmatrix}
  a_{11} & a_{12} & a_{13} \\
  a_{21} & a_{22} & a_{23}  \\
  a_{31} & a_{32} & a_{33} 
  \end{bmatrix}
  \left\{\begin{matrix}
  b_1 \\
  b_2 \\
  b_3 
  \end{matrix}\right\}
\end{equation}

::: {.fragment}
$$
c_1 = a_{11} b_1 + a_{12} b_2 + a_{13} b_3
$$

$$
c_2 = a_{21} b_1 + a_{22} b_2 + a_{23} b_3
$$

$$
c_3 = a_{31} b_1 + a_{32} b_2 + a_{33} b_3
$$
:::

::: {.fragment}
**In words:** $c_i$ is the dot product of the $i^{\mbox{th}}$ row of $\mathbf{a}$ with $\vec{b}$...
:::


---

## Matrix-Matrix multiplication

::: {.fragment}
\begin{equation}
\begin{bmatrix}
c_{11} & c_{12} & c_{13} \\
c_{21} & c_{22} & c_{23}  \\
c_{31} & c_{32} & c_{33} 
\end{bmatrix} = 
\begin{bmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23}  \\
a_{31} & a_{32} & a_{33} 
\end{bmatrix}
\begin{bmatrix}
b_{11} & b_{12} & b_{13} \\
b_{21} & b_{22} & b_{23}  \\
b_{31} & b_{32} & b_{33} 
\end{bmatrix}
\end{equation}
:::

::: {.fragment}
$$
c_{11} = a_{11} b_{11} + a_{12} b_{21} + a_{13} b_{31}
$$

\begin{align}
c_{12} &= a_{11} b_{12} + a_{12} b_{22} + a_{13} b_{32} \\
       & \vdots
\end{align}
:::

::: {.fragment}
**In words:** $c_{ij}$ is the dot product of the $i^{\mbox{th}}$ row of $\mathbf{a}$ with the $j^{\mbox{th}}$ column of $\mathbf{b}$
:::

---

## Examples

\begin{equation}
  \begin{bmatrix}
  2 & 1 \\
  3 & 2
  \end{bmatrix}
  \left\{
  \begin{matrix}
  1 \\
  2
  \end{matrix}\right\} = 
  \left\{\begin{matrix}
  4 \\
  7
  \end{matrix}\right\}
\end{equation}

::: {.fragment}
\begin{equation}
  \begin{bmatrix}
  2 & 1 \\
  3 & 2
  \end{bmatrix}
  \begin{bmatrix}
  1 & 3 \\
  1 & 2
  \end{bmatrix} = 
  \begin{bmatrix}
  3 & 8 \\
  5 & 13
  \end{bmatrix}
\end{equation}
:::

---

## The determinant of a 2 x 2 matrix

$$
\mathbf{A} = 
\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
$$


::: {.fragment}
$$
\det(\mathbf{A}) = a \cdot d - b \cdot c
$$
:::

---

## The determinant of a 3 x 3 matrix

$$
\mathbf{A} = 
\begin{bmatrix}
a & b & c\\
d & e & f\\
g & h & i
\end{bmatrix}
$$

::: {.fragment}
$$
\det(\mathbf{A}) = a \cdot ( e \cdot i - f \cdot h ) - b \cdot ( d \cdot i - f \cdot g ) + c \cdot ( d \cdot h - e \cdot g) 
$$
:::

---

## Matrix row operations

Used in solving matrix equations, i.e.

\begin{equation}
  \begin{bmatrix}
  a_{11} & a_{12} & a_{13} \\
  a_{21} & a_{22} & a_{23} \\
  a_{31} & a_{32} & a_{33}
  \end{bmatrix}
  \left\{
  \begin{matrix}
  x_1 \\
  x_2 \\
  x_3
  \end{matrix}
  \right\} =
  \left\{\begin{matrix}
  b_1 \\
  b_2 \\
  b_3
  \end{matrix}
  \right\}
\end{equation}

$$\mathbf{A}\vec{x} = \vec{b}$$


::: {.incremental}
- Swaping rows doesn't change solution
- Adding rows together doesn't change solution
- Multiplying row by a scalar doesn't change solution
:::


---

## Example

Solve for $\vec{x}$

\begin{equation}
\begin{bmatrix}
2 & 3 & -2 \\
0 & 0 & 3 \\
1 & 0 & 2 \\
\end{bmatrix}
\left\{
\begin{matrix}
x_1 \\
x_2 \\
x_3
\end{matrix}\right\} =
\left\{
\begin{matrix}
6 \\
-6 \\
3
\end{matrix}\right\}
\end{equation}

---

## Eigenvalue problem

$$
\mathbf{A} \vec{v} = \lambda \vec{v}
$$

::: {.notes}
A vector $\vec{v}$ is said to be an eigenvector of $\mathbf{A}$ if when multiplied by $\mathbf{A}$ on the right, it becomes a scalar multple of itself.
:::

::: {.fragment}
$$
\mathbf{A}\vec{v} - \lambda \vec{v} = 0
$$
:::

::: {.fragment}
$$
(\mathbf{A} - \lambda \mathbf{I})\vec{v} = 0
$$
:::


::: {.fragment}
A non-trivial solution for $\vec{v}$ exists, if and only if

$$
\det(\mathbf{A} - \lambda \mathbf{I}) = 0
$$

The $\lambda$'s are called the **eigenvalues**.  Examples to follow in the context of stress.
:::

---

## Vector transformation

$$
\vec{v}' = \mathbf{Q} \vec{v}
$$


$$
\mathbf{Q} =
\begin{bmatrix}
\cos(\theta) & \sin(\theta) \\
-\sin(\theta) & \cos(\theta)
\end{bmatrix}
$$

---

## Matrix transformation

$$
\mathbf{S}' = \mathbf{Q}^{-1} \mathbf{S} \mathbf{Q}
$$

::: {.fragment}
If $\mathbf{Q}$ is chosen such that its columns are eigenvectors of $\mathbf{S}$, then $\mathbf{S}'$ will be *diagonal* with its entries cooresponding to the eigenvalues $\mathbf{S}$ (and $\mathbf{S}'$).
:::
